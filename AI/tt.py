import argparse
import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
import segmentation_models_pytorch as smp

import time
from datetime import datetime

# ğŸ” COLOR_MAP ì •ì˜ (ì›ë³¸ ê·¸ëŒ€ë¡œ)
COLOR_MAP = {
    (230, 170, 255): 0, (0, 0, 255): 1, (0, 255, 0): 2, (255, 128, 255): 3,
    (255, 128, 0): 4, (255, 192, 0): 5, (255, 230, 153): 6, (255, 0, 0): 7,
    (138, 60, 200): 8, (55, 86, 35): 9, (217, 217, 217): 10, (110, 168, 70): 11,
    (198, 89, 17): 12, (128, 128, 128): 13, (255, 155, 155): 14, (88, 38, 128): 15,
    (255, 0, 255): 16, (208, 88, 255): 17, (0, 0, 0): 18
}

def index_to_color_mask(index_mask, color_map):
    h, w = index_mask.shape
    color_mask = np.zeros((h, w, 3), dtype=np.uint8)
    for rgb, idx in color_map.items():
        color_mask[index_mask == idx] = rgb
    return color_mask

def pad_to_multiple_of_8(img_tensor):
    _, _, h, w = img_tensor.shape
    new_h = ((h + 7) // 8) * 8
    new_w = ((w + 7) // 8) * 8
    pad_h = new_h - h
    pad_w = new_w - w
    # (left, right, top, bottom)
    padding = (0, pad_w, 0, pad_h)
    padded = F.pad(img_tensor, padding, mode="reflect")
    return padded, (h, w)

def main():
    parser = argparse.ArgumentParser(description="Semantic segmentation on Raspberry Pi")
    parser.add_argument("input",  help="ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("output", help="ì¶œë ¥ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--checkpoint", default="pspnet_epoch_3.pt",
                        help="í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()

    start_time = time.time()
    print(f"[{datetime.now()}] ğŸ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")

    # 1) ì¥ì¹˜ ì„¤ì • (CPUë§Œ ì‚¬ìš©)
    device = torch.device("cpu")

    # 2) ëª¨ë¸ ë¡œë“œ
    model = smp.PSPNet(
        encoder_name="resnet34",
        encoder_weights=None,
        in_channels=3,
        classes=len(COLOR_MAP)
    )
    checkpoint = torch.load(args.checkpoint, map_location=device)
    model.load_state_dict(checkpoint)
    model.to(device)
    model.eval()
    print(f"[{datetime.now()}] âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # 3) ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    img = Image.open(args.input).convert("RGB")
    img_np = np.array(img)
    # ToTensor: [0,255] -> [0,1], CxHxW
    img_tensor = torch.from_numpy(img_np).permute(2,0,1).float().div(255.0).unsqueeze(0).to(device)
    img_tensor, (orig_h, orig_w) = pad_to_multiple_of_8(img_tensor)

    # 4) ì¶”ë¡ 
    infer_start = time.time()
    with torch.no_grad():
        output = model(img_tensor)
        pred = torch.argmax(output, dim=1)[0].cpu().numpy()
    # 5) íŒ¨ë”© ì œê±°
    pred = pred[:orig_h, :orig_w]
    infer_end = time.time()
    print(f"[{datetime.now()}] ğŸ”® ì¶”ë¡  ì™„ë£Œ  (ì†Œìš”: {infer_end - infer_start:.3f}ì´ˆ)")

    # 6) ìƒ‰ìƒ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜
    mask_rgb = index_to_color_mask(pred, COLOR_MAP)
    mask_img = Image.fromarray(mask_rgb)
    print(f"[{datetime.now()}] ğŸ’¾ ë§ˆìŠ¤í¬ ì €ì¥ ì™„ë£Œ: {args.output}")

    # 7) ì €ì¥
    mask_img.save(args.output)
    print(f"ì˜ˆì¸¡ ë§ˆìŠ¤í¬ë¥¼ {args.output}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    end_time = time.time()
    print(f"[{datetime.now()}] ğŸ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ (ì´ ì†Œìš”: {end_time - start_time:.3f}ì´ˆ)")

if __name__ == "__main__":
    main()
